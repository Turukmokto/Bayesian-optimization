# Bayesian-optimization

Exercise:
1. Choose a supervised learning algorithm with a large number of hyperparameters.
2. Select a data set and an objective function of the algorithm evaluation.
3. Implement a Bayesian optimization algorithm.
4. Compare the Bayesian optimization algorithm with random search.
5. Visualize the space of tested hyperparameter values. Color mark the value of the objective function on them.
6. Visualize the objective function value depending on the step number.

Note:
1. The 5th and 6th steps should be performed for the Bayesian optimization algorithm and random search.
2. Any enhancement function is allowed: UCB, PI or EI.
3. You are allowed to use any surrogate function that is capable of estimating the uncertainty of the prediction. It is desirable to use random forest or Gaussian processes.
